{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1Dn3bgYkialkPXImM1XWaYqjgVNTGI9Fn",
      "authorship_tag": "ABX9TyOyEBS4a3xro8uMg3gOllPM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yasserius/satellite_image_tinhouse_detector/blob/main/training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaK-IZhwVfA1"
      },
      "source": [
        "# Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ei6tHCR8S-HD"
      },
      "source": [
        "Welcome to a tutorial on how to train your custom dataset on the TF2 Object Detection API.\n",
        "\n",
        "If you are looking for a model which draws bounding boxes around objects, then you have come to the right place.\n",
        "\n",
        "This tutorial is completely contained in a single Colab notebook, so there is no need to run any code on your computer.\n",
        "\n",
        "The main steps of the tutorial:\n",
        "1. Install the Object Detection API and other dependencies\n",
        "2. Load your data from Google Drive\n",
        "3. Convert the data into TFRecord files.\n",
        "4. Train the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zk9BTj_CTxUv"
      },
      "source": [
        "# References\n",
        "\n",
        "This tutorial has been heavily copied from the following awesome guides:\n",
        "- [Tensorflow Object Detection API Tutorial](https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/)\n",
        "- [Official Tensorflow Object Detection API Guides](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2.md)\n",
        "- [TF1 Object Detection Training on GCP](https://colab.research.google.com/github/cloud-annotations/google-colab-training/blob/master/object_detection.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beYp8GvHF0Tg"
      },
      "source": [
        "# Install the environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJv1XigBW1Vs"
      },
      "source": [
        "Python 3.6 and Tensorflow 2.3 should work for this to work."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TaIcuhCmWsQi",
        "outputId": "0aa7a265-4126-444e-f503-27b078d034c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!python --version"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python 3.6.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vQMqRUIWuuI",
        "outputId": "6a1c009f-234b-4314-add0-208100904254",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNPMw6AfU53K"
      },
      "source": [
        "## Setting directory locations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpaSgHotE0Ai"
      },
      "source": [
        "MODELS_DIR = \"/content/models\"\n",
        "OBJ_DET_DIR = \"/content/models/research/object_detection\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTVjyh5AU9_x"
      },
      "source": [
        "## Cloning from github"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "db0F8X6dEKMQ"
      },
      "source": [
        "Following the [official guide](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2.md) to install."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARLhiNZvDhzC",
        "outputId": "96a6eb0d-af89-45b8-d507-17eeaab0177c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "!git clone https://github.com/tensorflow/models.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 67, done.\u001b[K\n",
            "remote: Counting objects: 100% (67/67), done.\u001b[K\n",
            "remote: Compressing objects: 100% (65/65), done.\u001b[K\n",
            "remote: Total 46144 (delta 26), reused 43 (delta 2), pack-reused 46077\u001b[K\n",
            "Receiving objects: 100% (46144/46144), 551.17 MiB | 30.04 MiB/s, done.\n",
            "Resolving deltas: 100% (31629/31629), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjBPEgdvEChJ"
      },
      "source": [
        "%%bash\n",
        "cd models/research\n",
        "# Compile protos.\n",
        "protoc object_detection/protos/*.proto --python_out=.\n",
        "# Install TensorFlow Object Detection API.\n",
        "cp object_detection/packages/tf2/setup.py .\n",
        "python -m pip install ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9p8VkKUVtr7"
      },
      "source": [
        "## Adding paths to environment variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWDVme_oHpKG"
      },
      "source": [
        "import os\n",
        "\n",
        "main_dir = \"/content\"\n",
        "os.environ['PYTHONPATH'] += f':{main_dir}:{main_dir}/slim'\n",
        "os.environ['PYTHONPATH'] += f':{main_dir}:{main_dir}/models'\n",
        "os.environ['PYTHONPATH'] += f':{main_dir}:{main_dir}/models/research'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-iZD5YUWV2eA"
      },
      "source": [
        "## Testing the installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZR-yjhoQER2e"
      },
      "source": [
        "!python \"$OBJ_DET_DIR/builders/model_builder_tf2_test.py\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbxfrBjuWOTC"
      },
      "source": [
        "There will be a really long output.\n",
        "\n",
        "But if the installation succeeded, you should see something like this at the bottom:\n",
        "\n",
        "```\n",
        "----------------------------------------------------------------------\n",
        "Ran 20 tests in 45.495s\n",
        "\n",
        "OK (skipped=1)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nlcf5lxMF9Hw"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-3GMqZvXQWw"
      },
      "source": [
        "## How to label your data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhJHPJLlXVfg"
      },
      "source": [
        "Your data must be either JPG or PNG format images, and the annotations must be in [PASCAL VOC XML format](https://gist.github.com/Prasad9/30900b0ef1375cc7385f4d85135fdb44).\n",
        "\n",
        "The best way to annotate for this tutorial is to follow [this tutorial](https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/training.html#annotate-the-dataset), which uses [LabelImg](https://github.com/tzutalin/labelImg) to annotate the images.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_sndH0CcrcT"
      },
      "source": [
        "<img src=\"https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/_images/labelImg.JPG\" height=300px>\n",
        "\n",
        "<small>LabelImg</small>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nauFgnB-anV6"
      },
      "source": [
        "Once you have the data, upload it to Google Drive and paste the directory path in the `G_DRIVE_PATH` below.\n",
        "\n",
        "The data folder must contain all the images and XML files in it, like this:\n",
        "```\n",
        "1.jpg\n",
        "1.xml\n",
        "2.jpg\n",
        "2.xml\n",
        "...\n",
        "```\n",
        "Make sure the names of the images and XML files are the same. The names don't have to be numbers, they can be anything."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-oNKu38dwhw"
      },
      "source": [
        "## Copying your data to colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECoM5XZma7G6"
      },
      "source": [
        "# Paste your path here.\n",
        "G_DRIVE_PATH = '/content/drive/My Drive/data/satellite_images_dhaka/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2AiULsfdNhi"
      },
      "source": [
        "Mount Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-T_esT6LG9Zl",
        "outputId": "c6f3b7f2-e420-49dd-d82d-7c7172d734f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBZnWqqudP71"
      },
      "source": [
        "Your images and XML files will be copied to `DATA_DIR`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWvNWI4GG5vv"
      },
      "source": [
        "DATA_DIR = \"/content/data\"\n",
        "\n",
        "!mkdir \"$DATA_DIR\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8O5vw8ZGdbD_"
      },
      "source": [
        "Check to see if Google Drive contains your data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4cDXLxJIPtG",
        "outputId": "25be82c6-5c2f-44ae-95a6-60de6effc66c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "import glob\n",
        "from pprint import pprint\n",
        "\n",
        "images_paths = glob.glob(G_DRIVE_PATH + \"*.png\")\n",
        "images_paths = sorted(images_paths)\n",
        "\n",
        "pprint(images_paths[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['/content/drive/My Drive/data/satellite_images_dhaka/0_1.png',\n",
            " '/content/drive/My Drive/data/satellite_images_dhaka/0_10.png',\n",
            " '/content/drive/My Drive/data/satellite_images_dhaka/0_11.png',\n",
            " '/content/drive/My Drive/data/satellite_images_dhaka/0_12.png',\n",
            " '/content/drive/My Drive/data/satellite_images_dhaka/0_13.png',\n",
            " '/content/drive/My Drive/data/satellite_images_dhaka/0_14.png',\n",
            " '/content/drive/My Drive/data/satellite_images_dhaka/0_15.png',\n",
            " '/content/drive/My Drive/data/satellite_images_dhaka/0_16.png',\n",
            " '/content/drive/My Drive/data/satellite_images_dhaka/0_5.png',\n",
            " '/content/drive/My Drive/data/satellite_images_dhaka/0_6.png']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPBT1D00EcA5",
        "outputId": "2a920087-d9f6-470a-e3f2-7f0bb4f3b18a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(images_paths))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1260\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2qVAM3TdpeQ"
      },
      "source": [
        "## Train-Validation Split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MMFjjRnd4iQ"
      },
      "source": [
        "The train data receives 90% by default, but you can change `TRAIN_SPLIT` to something like 80 or 95."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3GKK4JyEUrj"
      },
      "source": [
        "from random import shuffle\n",
        "\n",
        "TRAIN_SPLIT = 90\n",
        "\n",
        "limit = int(len(images_paths) * TRAIN_SPLIT / 100)\n",
        "\n",
        "shuffle(images_paths)\n",
        "train_images = images_paths[:limit]\n",
        "val_images = images_paths[limit:]\n",
        "\n",
        "print(\"Number of train images:\", len(train_images))\n",
        "print(\"Number of validation images:\", len(val_images))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJrKk8J_ed4B"
      },
      "source": [
        "The train images and annotations will be copied to `/content/data/train` and the validation ones to `/content/data/val`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1qEcO64JHrl"
      },
      "source": [
        "from IPython.display import display, clear_output\n",
        "from shutil import copyfile\n",
        "import os\n",
        "\n",
        "TRAIN_DATA_DIR = os.path.join(DATA_DIR, \"train\")\n",
        "VAL_DATA_DIR = os.path.join(DATA_DIR, \"val\")\n",
        "\n",
        "!mkdir $TRAIN_DATA_DIR\n",
        "!mkdir $VAL_DATA_DIR\n",
        "\n",
        "for i, img_path in enumerate(train_images):\n",
        "  img_name = img_path.split(\"/\")[-1]\n",
        "  xml_path = img_path.replace(\".png\", \".xml\")\n",
        "  xml_name = img_name.replace(\".png\", \".xml\")\n",
        "\n",
        "  if i%100 == 0:\n",
        "    clear_output(wait=True)\n",
        "    display(\"Copying {} out of {} files.\".format(i, len(train_images)))\n",
        "\n",
        "  destination = TRAIN_DATA_DIR\n",
        "\n",
        "  copyfile(img_path,\n",
        "           os.path.join(destination, img_name))\n",
        "  copyfile(xml_path,\n",
        "           os.path.join(destination, xml_name))\n",
        "  \n",
        "print(\"Successfully copied train data to {}\".format(TRAIN_DATA_DIR))\n",
        "\n",
        "for i, img_path in enumerate(val_images):\n",
        "  img_name = img_path.split(\"/\")[-1]\n",
        "  xml_path = img_path.replace(\".png\", \".xml\")\n",
        "  xml_name = img_name.replace(\".png\", \".xml\")\n",
        "\n",
        "  if i%100 == 0:\n",
        "    clear_output(wait=True)\n",
        "    display(\"Copying {} out of {} files.\".format(i, len(val_images)))\n",
        "\n",
        "  destination = VAL_DATA_DIR\n",
        "\n",
        "  copyfile(img_path,\n",
        "           os.path.join(destination, img_name))\n",
        "  copyfile(xml_path,\n",
        "           os.path.join(destination, xml_name))\n",
        "  \n",
        "print(\"Successfully copied validation data to {}\".format(VAL_DATA_DIR))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFfuWE54e2Bv"
      },
      "source": [
        "Test to see if the files were copied properly:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKMJMFm_AlJ1",
        "outputId": "41e03185-af43-45c9-84b2-08e27375b969",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print(\"# images in train dir:\", len(glob.glob(TRAIN_DATA_DIR + \"/*.png\")))\n",
        "print(\"# XML in train dir:\", len(glob.glob(TRAIN_DATA_DIR + \"/*.xml\")))\n",
        "print(\"# images in validation dir:\", len(glob.glob(VAL_DATA_DIR + \"/*.png\")))\n",
        "print(\"# XML in train dir:\", len(glob.glob(VAL_DATA_DIR + \"/*.xml\")))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1134\n",
            "1134\n",
            "126\n",
            "126\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39EBoBhJ-fyN"
      },
      "source": [
        "# Generate TFRecords"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LpLdGBANfW7Z"
      },
      "source": [
        "Now that all the data has been copied to colab, it must be converted to TFRecords format, because the Object Detection API uses it. You can read more about the record format online.\n",
        "\n",
        "I adapted this [official script](https://github.com/tensorflow/models/blob/master/research/object_detection/dataset_tools/create_pascal_tf_record.py) and created a github [gist](https://gist.github.com/yasserius/ef9eb79c3f2f516ed1e4f793150d6f76), which is what is being used in the following steps."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reo2oTmhgJIK"
      },
      "source": [
        "The `train.record` and `val.record` files will be stored in the `/content/data` directory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qt16u5iA-swV"
      },
      "source": [
        "TRAIN_TFRECORD_PATH = os.path.join(DATA_DIR, \"train.record\")\n",
        "VAL_TFRECORD_PATH = os.path.join(DATA_DIR, \"val.record\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-r-NoOgkgo-I"
      },
      "source": [
        "Downloading the gist as a file named `tfrecord_generator.py`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQbc_Kq4xok9",
        "outputId": "d12bf55a-d081-4071-866c-e8ecf4cef70d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "!wget https://gist.githubusercontent.com/yasserius/ef9eb79c3f2f516ed1e4f793150d6f76/raw/20cee1a342d79e24b649a7b3dbc9500be832ce6f/tfrecord_generator.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-10-22 06:00:52--  https://gist.githubusercontent.com/yasserius/ef9eb79c3f2f516ed1e4f793150d6f76/raw/20cee1a342d79e24b649a7b3dbc9500be832ce6f/tfrecord_generator.py\n",
            "Resolving gist.githubusercontent.com (gist.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to gist.githubusercontent.com (gist.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6460 (6.3K) [text/plain]\n",
            "Saving to: ‘tfrecord_generator.py’\n",
            "\n",
            "tfrecord_generator. 100%[===================>]   6.31K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-10-22 06:00:52 (72.2 MB/s) - ‘tfrecord_generator.py’ saved [6460/6460]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrjQ0YgOg2TC"
      },
      "source": [
        "The script does two things:\n",
        "1. It generates a `label_map.pbtxt` file, which contains all the class names and their indices.\n",
        "2. It generates `train.record` and `val.record` using the image and XML files."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wX5yTNJGhSwC"
      },
      "source": [
        "## Generating label map file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1snSWZU5YFi",
        "outputId": "80304f2d-0262-4a36-aade-a5107680fb3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "from tfrecord_generator import create_tfrecords, generate_label_map\n",
        "\n",
        "LABEL_MAP_PATH = os.path.join(DATA_DIR, \"label_map.pbtxt\")\n",
        "\n",
        "label_map_dict = generate_label_map(TRAIN_DATA_DIR, output_path=LABEL_MAP_PATH)\n",
        "\n",
        "print(label_map_dict)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/object_detection/utils/dataset_util.py:79: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
            "  if not xml:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Successfully created /content/data/label_map.pbtxt\n",
            "{'house': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpmc4wkshWV_"
      },
      "source": [
        "## Generating TFRecord files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPmujHsz5yXa",
        "outputId": "4107dd80-1312-4075-e0a5-732d2999a5df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "create_tfrecords(TRAIN_DATA_DIR,\n",
        "                 output_path=TRAIN_TFRECORD_PATH,\n",
        "                 label_map_dict=label_map_dict)\n",
        "\n",
        "create_tfrecords(VAL_DATA_DIR,\n",
        "                 output_path=VAL_TFRECORD_PATH,\n",
        "                 label_map_dict=label_map_dict)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/object_detection/utils/dataset_util.py:79: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
            "  if not xml:\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFJcCnFyhi-P"
      },
      "source": [
        "Check the size of the record files to check if the files are proper. The sizes are shown in bytes, and should be close to your raw data size."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJYI044SLnRA",
        "outputId": "af6afa7a-5bfe-49a6-ef44-cca51d1038cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!stat -c%s \"$TRAIN_TFRECORD_PATH\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "338842333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6omKqrboKaKh",
        "outputId": "fd743e29-860c-4663-82a4-e401423f2845",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!stat -c%s \"$VAL_TFRECORD_PATH\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "38516541\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qh3Resi1iJsL"
      },
      "source": [
        "## (Optional) copy record files to google drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXgFQRoGiO-n"
      },
      "source": [
        "Since colab will lose the record files with the session, it is best that copy them back into drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NALSLvUw6aOp"
      },
      "source": [
        "!cp \"$TRAIN_TFRECORD_PATH\" \"$G_DRIVE_PATH\"\n",
        "!cp \"$VAL_TFRECORD_PATH\" \"$G_DRIVE_PATH\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lT6aSoLlJw2p"
      },
      "source": [
        "# Download pretrained model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6e_MMkgi0Iw"
      },
      "source": [
        "## Paste the link to pretrained mdoel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDE5Fk-dibvv"
      },
      "source": [
        "You must choose a pretrained model from [TF2 Model Zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md).\n",
        "\n",
        "Then paste the link to the tar file below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GY0C_TIJ0YG"
      },
      "source": [
        "MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShifULFwi5SP"
      },
      "source": [
        "## Downloading to checkpoint directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tuxdBbdui-aW"
      },
      "source": [
        "The downlaoded model will be in `/content/pretrained`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OneFifYrJaGS",
        "outputId": "f38e5fa7-32db-43d1-883b-7884d052cc5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "source": [
        "CHECKPOINT_DIR = \"/content/pretrained\"\n",
        "\n",
        "filename = MODEL_URL.split('/')[-1]\n",
        "\n",
        "!mkdir \"$CHECKPOINT_DIR\"\n",
        "!wget $MODEL_URL\n",
        "!tar -xzvf \"$filename\" -C \"$CHECKPOINT_DIR\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-10-22 13:44:40--  http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz\n",
            "Resolving download.tensorflow.org (download.tensorflow.org)... 74.125.26.128, 2607:f8b0:400c:c04::80\n",
            "Connecting to download.tensorflow.org (download.tensorflow.org)|74.125.26.128|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 244817203 (233M) [application/x-tar]\n",
            "Saving to: ‘ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz’\n",
            "\n",
            "ssd_resnet50_v1_fpn 100%[===================>] 233.48M  74.6MB/s    in 3.1s    \n",
            "\n",
            "2020-10-22 13:44:43 (74.6 MB/s) - ‘ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz’ saved [244817203/244817203]\n",
            "\n",
            "ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/\n",
            "ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/checkpoint/\n",
            "ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n",
            "ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/checkpoint/checkpoint\n",
            "ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/checkpoint/ckpt-0.index\n",
            "ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/pipeline.config\n",
            "ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/saved_model/\n",
            "ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/saved_model/saved_model.pb\n",
            "ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/saved_model/assets/\n",
            "ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/saved_model/variables/\n",
            "ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/saved_model/variables/variables.data-00000-of-00001\n",
            "ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/saved_model/variables/variables.index\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PeX_onzLKtw6"
      },
      "source": [
        "The following files are needed for our training:\n",
        "1. `ckpt-0`\n",
        "2. `pipeline.config`\n",
        "\n",
        "This program gets them and stores them in `PIPELINE_TEMPLATE_PATH` and `CKPT_PATH`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5AbR-InjgLc",
        "outputId": "5f04c59d-6424-471e-d588-a5e7012724b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import os\n",
        "\n",
        "PIPELINE_TEMPLATE_PATH = None\n",
        "CKPT_PATH = None\n",
        "\n",
        "for dir, subdirs, files in os.walk(CHECKPOINT_DIR):\n",
        "  if \"pipeline.config\" in files:\n",
        "    PIPELINE_TEMPLATE_PATH = os.path.join(dir, \"pipeline.config\")\n",
        "    print(PIPELINE_TEMPLATE_PATH)\n",
        "  elif \"ckpt-0.data-00000-of-00001\" in files:\n",
        "    CKPT_PATH = os.path.join(dir, \"ckpt-0.data-00000-of-00001\")\n",
        "    print(CKPT_PATH)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/pretrained/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/pipeline.config\n",
            "/content/pretrained/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vr5ARYQ7K1Xz"
      },
      "source": [
        "# Editing configuration file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJDOfd4ylntA"
      },
      "source": [
        "The `pipeline.config` file is very important, since it contains all the trianing parameters and paths to all the record files.\n",
        "\n",
        "The following program edits that.\n",
        "\n",
        "You can increase or decrease the batch size. If you have small images like MNIST, use 32. But if each image is large like 1000x1000, then use 2 or 4."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXTmF0INLKWM"
      },
      "source": [
        "BATCH_SIZE = 8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Y5m5JniKvM0",
        "outputId": "ac9deb3a-80c3-4127-c004-9ea18055c7eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "import re\n",
        "\n",
        "from google.protobuf import text_format\n",
        "\n",
        "from object_detection.utils import config_util\n",
        "from object_detection.utils import label_map_util\n",
        "\n",
        "configs = config_util.get_configs_from_pipeline_file(PIPELINE_TEMPLATE_PATH)\n",
        "\n",
        "label_map = label_map_util.get_label_map_dict(LABEL_MAP_PATH)\n",
        "num_classes = len(label_map.keys())\n",
        "meta_arch = configs[\"model\"].WhichOneof(\"model\")\n",
        "\n",
        "override_dict = {\n",
        "  'model.{}.num_classes'.format(meta_arch): num_classes,\n",
        "  'train_config.batch_size': BATCH_SIZE,\n",
        "  'train_input_path': TRAIN_TFRECORD_PATH,\n",
        "  'eval_input_path': VAL_TFRECORD_PATH,\n",
        "  'train_config.fine_tune_checkpoint': CKPT_PATH,\n",
        "  'train_config.fine_tune_checkpoint_type': \"detection\",\n",
        "  'label_map_path': LABEL_MAP_PATH\n",
        "}\n",
        "\n",
        "configs = config_util.merge_external_params_with_configs(configs, kwargs_dict=override_dict)\n",
        "pipeline_config = config_util.create_pipeline_proto_from_configs(configs)\n",
        "config_util.save_pipeline_config(pipeline_config, DATA_DIR)\n",
        "\n",
        "print(\"Successfully created configuration file.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Maybe overwriting model.ssd.num_classes: 1\n",
            "INFO:tensorflow:Maybe overwriting train_config.batch_size: 8\n",
            "INFO:tensorflow:Maybe overwriting train_input_path: /content/data/train.record\n",
            "INFO:tensorflow:Maybe overwriting eval_input_path: /content/data/val.record\n",
            "INFO:tensorflow:Maybe overwriting train_config.fine_tune_checkpoint: /content/pretrained/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/checkpoint/ckpt-0\n",
            "INFO:tensorflow:Maybe overwriting train_config.fine_tune_checkpoint_type: detection\n",
            "INFO:tensorflow:Maybe overwriting label_map_path: /content/data/label_map.pbtxt\n",
            "INFO:tensorflow:Writing pipeline config file to /content/data/pipeline.config\n",
            "Successfully created configuration file.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXxHiQn8mN8H"
      },
      "source": [
        "You can view the final file from the left panel at `/content/data/pipeline.config`. \n",
        "\n",
        "If you are more interested, you can read these links too: [1](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/configuring_jobs.md), [2](https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/training.html#configure-the-training-pipeline)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVHSh0AjL5sq"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEf5w_Cim6SY"
      },
      "source": [
        "Finally, your model is ready to train."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JL6MpbPQnHIu"
      },
      "source": [
        "The checkpoints (`ckpt` weight files) at different stages of the training will be stored in `OUTPUT_PATH`.\n",
        "\n",
        "Since colab is not super reliable and often disconnects, it might be the case that you lose your trained checkpoints. So, it is best that you store the checkpoints in drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zdpp9fErnPwZ"
      },
      "source": [
        "OUTPUT_PATH = os.path.join(G_DRIVE_PATH, \"training_oct_10\")\n",
        "\n",
        "# uncomment this is you want to store the checkpoints in colab\n",
        "# OUTPUT_PATH = \"/content/training\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RihL1r0jn3Zg"
      },
      "source": [
        "If you wish to monitor the training via colab, run the following cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-FEI7juL6_c"
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir=$OUTPUT_PATH"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQFtz_n0ohgB"
      },
      "source": [
        "Now begins the long process of training.\n",
        "\n",
        "* You can tweak the `--checkpoint_every_n=100 ` to some other value. Use 200 or 300 if you want to store less checkpoints, and 10 or 50 if you want checkpoints more often.\n",
        "\n",
        "* Keep in mind, colab will allow you a maximum of 12 hours of training.\n",
        "\n",
        "* Also, paste this [javascript code](https://www.rockyourcode.com/script-to-stop-google-colab-from-disconnecting/) into the browser console to prevent colab from disconnecting.\n",
        "\n",
        "* Finally, after you run the script, **it takes time to show the training process. BE PATIENT!**\n",
        "\n",
        "* There will be a lot of warnings, no worries. And every 100 time steps later (which might be 1 or 2 hours), it will print the loss like this:\n",
        "```\n",
        "I1021 14:56:54.731037 140444534626176 model_lib_v2.py:652] Step 100 per-step time 64.361s loss=6.536\n",
        "```\n",
        "\n",
        "* To see detailed output of what is expected, see [this](https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/training.html#training-the-model)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oypcrzXFqzQZ"
      },
      "source": [
        "Run the script!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mx6r5c61MKeN"
      },
      "source": [
        "PIPELINE_CONFIG_PATH = \"/content/data/pipeline.config\"\n",
        "TRAIN_FILE = \"/content/models/research/object_detection/model_main_tf2.py\"\n",
        "\n",
        "!mkdir \"$OUTPUT_PATH\"\n",
        "\n",
        "!python  $TRAIN_FILE \\\n",
        "    --alsologtostderr\n",
        "    --pipeline_config_path=\"$PIPELINE_CONFIG_PATH\" \\\n",
        "    --model_dir=\"$OUTPUT_PATH\" \\\n",
        "    --checkpoint_every_n=100 \\"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-i1arlyQijC"
      },
      "source": [
        "# Export model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8EyntloTQY6u"
      },
      "source": [
        "Once the loss decreases to about 0.1, you can stop training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ew2JS4kOxTs"
      },
      "source": [
        "EXPORT_DIR = os.path.join(G_DRIVE_PATH, \"export\")\n",
        "\n",
        "!mkdir \"$EXPORT_DIR\"\n",
        "\n",
        "!python \"$OBJ_DET_DIR/exporter_main_v2.py\" \\\n",
        "  --input_type='image_tensor' \\\n",
        "  --pipeline_config_path=\"$PIPELINE_CONFIG_PATH\"  \\\n",
        "  --trained_checkpoint_dir=\"$OUTPUT_PATH\" \\\n",
        "  --output_directory=\"$EXPORT_DIR\""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}